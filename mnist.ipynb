{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random \n",
    "\n",
    "def get_client_loaders(num_clients=3):\n",
    "    cifar_train = datasets.CIFAR10(root='./data_cifar', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "    client_data = []\n",
    "    samples_per_client = len(cifar_train) // num_clients\n",
    "    for i in range(num_clients):\n",
    "        indices = range(i * samples_per_client, (i+1) * samples_per_client)\n",
    "        client_data.append(Subset(cifar_train, indices))\n",
    "    \n",
    "    client_loaders = [DataLoader(data, batch_size=BATCH_SIZE, shuffle=True, drop_last=False) for data in client_data]\n",
    "    return client_loaders\n",
    "\n",
    "def get_imbalanced_client_loaders(num_clients=3):\n",
    "    client_data = []\n",
    "    cifar_train = datasets.CIFAR10(root='./data_cifar', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "    cifar_common = Subset(cifar_train, range(5000))\n",
    "    cifar_train = Subset(cifar_train, range(5000, len(cifar_train)))\n",
    "    \n",
    "    class_indices = defaultdict(list)\n",
    "    for idx, (_, label) in enumerate(cifar_train):\n",
    "        class_indices[label].append(idx)\n",
    "    for i in range(num_clients):\n",
    "        client_indices = []\n",
    "        client_classes = random.sample(range(10), 7)\n",
    "        for obj_class in client_classes:\n",
    "            client_indices += random.sample(class_indices[obj_class], 50)\n",
    "        client_data.append(Subset(cifar_train, client_indices))\n",
    "    client_loaders = [DataLoader(data, batch_size=BATCH_SIZE, shuffle=True, drop_last=False) for data in client_data]\n",
    "    common_loader = DataLoader(cifar_common, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "    return client_loaders, common_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_train(model, loader, epochs=1):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_loder = DataLoader(datasets.CIFAR10(root='./data_cifar', train=False, download=True, transform=transform), batch_size=BATCH_SIZE, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_models = [SimpleCNN().to(device) for _ in range(num_clients)]\n",
    "client_loaders, common_loader = get_imbalanced_client_loaders(num_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientState:\n",
    "    def __init__(self, model, lmbd = 0.1, gamma = 0.1):\n",
    "        self.weights = []\n",
    "        self.state = [torch.zeros_like(p) for p in model.parameters()]\n",
    "        self.prev_state = [torch.zeros_like(p) for p in model.parameters()]\n",
    "        self.lmbd = lmbd\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def local_step(self, model):\n",
    "        for idx, param in enumerate(model.parameters()):\n",
    "            self.state[idx] += param.grad - self.prev_state[idx]\n",
    "            self.prev_state[idx] = param.grad\n",
    "            param.grad = torch.zeros_like(param.grad)\n",
    "    \n",
    "    def global_step(self, model):\n",
    "        for idx, param in enumerate(model.parameters()):\n",
    "            self.state[idx] = param.grad\n",
    "            self.prev_state[idx] = param.grad\n",
    "            param.grad = torch.zeros_like(param.grad)\n",
    "\n",
    "    def set_weights(self, model):\n",
    "        self.weights = [p for p in model.parameters()]\n",
    "\n",
    "    def get_reg_term(self, model):\n",
    "        l2_regularization = torch.tensor(0., requires_grad=True)\n",
    "        for idx, (param, x, g) in enumerate(zip(model.parameters(), self.weights, self.state)):\n",
    "            l2_regularization = l2_regularization + torch.norm(param - (x - self.gamma * self.lmbd * g), p=2)\n",
    "        return l2_regularization * 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_top_k(logits, k = 3):\n",
    "    size = logits.size()\n",
    "    _, indices = torch.topk(logits, k, dim= -1)\n",
    "    sparse_logits = torch.gather(logits, dim=-1, index=indices).to(logits.device)\n",
    "    return sparse_logits, indices, size\n",
    "\n",
    "def decomp_top_k(sparse_logits, indices, size):\n",
    "    decomp_logits  = torch.zeros(size, dtype= sparse_logits.dtype, device= sparse_logits.device)\n",
    "    decomp_logits.scatter_(-1, indices, sparse_logits)\n",
    "    return decomp_logits"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def dithering(logits, b = 2, s = 8, p = 2):\n",
    "    norm_logits = torch.norm(logits.float(), p, dim=-1, keepdim=True)\n",
    "    normalized_logits = logits.abs() / norm_logits\n",
    "    levels = b ** -torch.arange(1, s + 1, dtype=logits.dtype, device=logits.device)  \n",
    "    levels = torch.cat([torch.tensor([1.0], device=logits.device, dtype=logits.dtype), levels, torch.tensor([0.0], device=logits.device, dtype=logits.dtype)])\n",
    "    u = torch.sum(normalized_logits.unsqueeze(-1) <= levels.unsqueeze(0), dim=-1, dtype= float) \n",
    "    lower = b ** -u\n",
    "    upper = b ** -(u - 1)\n",
    "    lower = torch.where(u == 10, 0.0, lower)\n",
    "    probs_upper = (normalized_logits - lower) / (upper - lower)\n",
    "    bern = torch.bernoulli(probs_upper)\n",
    "    quantized = torch.where(bern == 1, upper, lower)\n",
    "    result = norm_logits * torch.sign(logits) * quantized\n",
    "    return result"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def comp_rand_k(logits, k = 3):\n",
    "    seed = random.randint(0, 1000)\n",
    "    torch.manual_seed(seed)\n",
    "    size = logits.size()\n",
    "    new_size = size[:-1] + (k,)\n",
    "    sparse_logits = torch.zeros(new_size, dtype= logits.dtype)\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            indices = torch.randperm(size[-1], device=logits.device)[:k]\n",
    "            indices, _ = torch.sort(indices)\n",
    "            sparse_logits[i, j] = logits[i, j, indices]\n",
    "    sparse_logits *= size[-1] / k\n",
    "    return sparse_logits, seed, size\n",
    "\n",
    "def decomp_rand_k(sparse_logits, seed, size, k = 3):\n",
    "    torch.manual_seed(seed)\n",
    "    decomp_logits  = torch.full(size, float('-inf') ,dtype= sparse_logits.dtype)\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            indices = torch.randperm(size[-1], device=sparse_logits.device)[:k]\n",
    "            indices, _ = torch.sort(indices)\n",
    "            decomp_logits[i, j, indices] = sparse_logits[i, j]\n",
    "    return decomp_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "clients_states = [ClientState(model) for model in client_models]\n",
    "client_optimizers = [\n",
    "    optim.Adam(model.parameters())\n",
    "    for model in client_models\n",
    "]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "class DifferentiableCompress(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        return x#decomp_top_k(*comp_top_k(x))\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output\n",
    "\n",
    "def sync_clients(batch):\n",
    "    inputs, target = batch\n",
    "    inputs = inputs.to(device)\n",
    "    target = target.to(device)\n",
    "    logits = []\n",
    "    for model in client_models:\n",
    "        raw_out = model(inputs)\n",
    "        compressed = DifferentiableCompress.apply(raw_out)\n",
    "        logits.append(compressed)\n",
    "    \n",
    "    logits = torch.stack(logits)\n",
    "    logits = logits.mean(0)\n",
    "    loss = criterion(logits, target)\n",
    "    loss.backward()\n",
    "\n",
    "def run_step(p, iter_idx):\n",
    "    if random.random() > p:\n",
    "        batch = next(iter(common_loader))\n",
    "        sync_clients(batch)\n",
    "        for model, state in zip(client_models, clients_states):\n",
    "            state.global_step(model)\n",
    "    else:\n",
    "        for model, state, loader in zip(client_models, clients_states, client_loaders):\n",
    "            inputs, target = next(iter(loader))\n",
    "            inputs = inputs.to(device)\n",
    "            target = target.to(device)\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, target)\n",
    "            loss.backward()\n",
    "            state.local_step(model)\n",
    "    \n",
    "    for model, state, loader, optimizer in zip(client_models, clients_states, client_loaders, client_optimizers):\n",
    "        state.set_weights(model)\n",
    "        for _ in range(10):\n",
    "            inputs, target = next(iter(loader))\n",
    "            inputs = inputs.to(device)\n",
    "            target = target.to(device)\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, target) * state.gamma\n",
    "            reg = state.get_reg_term(model)\n",
    "            loss += reg\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging(iter_idx):\n",
    "    local_accuracy = torch.tensor([evaluate(model, loader) for model, loader in zip(client_models, client_loaders)])\n",
    "    single_accuracy = torch.tensor([evaluate(model, validation_loder) for model in client_models])\n",
    "    writer.add_scalars(\n",
    "        main_tag='Accuracy',\n",
    "        tag_scalar_dict={'local': local_accuracy.mean(), 'single': single_accuracy.mean()},\n",
    "        global_step=iter_idx\n",
    "    )\n",
    "    print(f\"Single accuracy = {single_accuracy.mean():.2f} +- {single_accuracy.std():.2f} || Local accuracy = {local_accuracy.mean():.2f} +- {local_accuracy.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single accuracy = 0.10 +- 0.01 || Local accuracy = 0.08 +- 0.07\n",
      "Single accuracy = 0.29 +- 0.02 || Local accuracy = 0.79 +- 0.07\n",
      "Single accuracy = 0.28 +- 0.02 || Local accuracy = 1.00 +- 0.00\n",
      "Single accuracy = 0.27 +- 0.02 || Local accuracy = 1.00 +- 0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m i % \u001B[32m10\u001B[39m == \u001B[32m0\u001B[39m:\n\u001B[32m      3\u001B[39m     logging(i)\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \u001B[43mrun_step\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 52\u001B[39m, in \u001B[36mrun_step\u001B[39m\u001B[34m(p, iter_idx)\u001B[39m\n\u001B[32m     50\u001B[39m state.set_weights(model)\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m10\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m     inputs, target = \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mloader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     53\u001B[39m     inputs = inputs.to(device)\n\u001B[32m     54\u001B[39m     target = target.to(device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/torch/utils/data/dataloader.py:734\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    731\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    732\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    733\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m734\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    735\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    736\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    737\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    738\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    739\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    740\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/torch/utils/data/dataloader.py:790\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    788\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    789\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m790\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    791\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    792\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:50\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     48\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.auto_collation:\n\u001B[32m     49\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.dataset, \u001B[33m\"\u001B[39m\u001B[33m__getitems__\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.dataset.__getitems__:\n\u001B[32m---> \u001B[39m\u001B[32m50\u001B[39m         data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m.\u001B[49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     51\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     52\u001B[39m         data = [\u001B[38;5;28mself\u001B[39m.dataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/torch/utils/data/dataset.py:414\u001B[39m, in \u001B[36mSubset.__getitems__\u001B[39m\u001B[34m(self, indices)\u001B[39m\n\u001B[32m    410\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__getitems__\u001B[39m(\u001B[38;5;28mself\u001B[39m, indices: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mint\u001B[39m]) -> \u001B[38;5;28mlist\u001B[39m[_T_co]:\n\u001B[32m    411\u001B[39m     \u001B[38;5;66;03m# add batched sampling support when parent dataset supports it.\u001B[39;00m\n\u001B[32m    412\u001B[39m     \u001B[38;5;66;03m# see torch.utils.data._utils.fetch._MapDatasetFetcher\u001B[39;00m\n\u001B[32m    413\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.dataset, \u001B[33m\"\u001B[39m\u001B[33m__getitems__\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)):\n\u001B[32m--> \u001B[39m\u001B[32m414\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m.\u001B[49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[32m    415\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    416\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m.dataset[\u001B[38;5;28mself\u001B[39m.indices[idx]] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/torch/utils/data/dataset.py:416\u001B[39m, in \u001B[36mSubset.__getitems__\u001B[39m\u001B[34m(self, indices)\u001B[39m\n\u001B[32m    414\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.dataset.__getitems__([\u001B[38;5;28mself\u001B[39m.indices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[32m    415\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m416\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/torchvision/datasets/cifar.py:116\u001B[39m, in \u001B[36mCIFAR10.__getitem__\u001B[39m\u001B[34m(self, index)\u001B[39m\n\u001B[32m    112\u001B[39m img, target = \u001B[38;5;28mself\u001B[39m.data[index], \u001B[38;5;28mself\u001B[39m.targets[index]\n\u001B[32m    114\u001B[39m \u001B[38;5;66;03m# doing this so that it is consistent with all other datasets\u001B[39;00m\n\u001B[32m    115\u001B[39m \u001B[38;5;66;03m# to return a PIL Image\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m img = \u001B[43mImage\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfromarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    119\u001B[39m     img = \u001B[38;5;28mself\u001B[39m.transform(img)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.13/site-packages/PIL/Image.py:3300\u001B[39m, in \u001B[36mfromarray\u001B[39m\u001B[34m(obj, mode)\u001B[39m\n\u001B[32m   3298\u001B[39m shape = arr[\u001B[33m\"\u001B[39m\u001B[33mshape\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m   3299\u001B[39m ndim = \u001B[38;5;28mlen\u001B[39m(shape)\n\u001B[32m-> \u001B[39m\u001B[32m3300\u001B[39m strides = \u001B[43marr\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstrides\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m   3301\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   3302\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    if i % 10 == 0:\n",
    "        logging(i)\n",
    "    run_step(0.2, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
