{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "differrent_num_clients = [10]\n",
    "num_clients_balanced_our = {}\n",
    "num_clients_imbalanced_our = {}\n",
    "num_clients_balanced_their = {}\n",
    "num_clients_imbalanced_their = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.fc = nn.Linear(16 * 28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = x.view(-1, 16 * 28 * 28)\n",
    "        return self.fc(x)\n",
    "\n",
    "global_model = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client_loaders(num_clients=3):\n",
    "    transform = transforms.ToTensor()\n",
    "    mnist_train = datasets.MNIST(root='./data_mnist', train=True, download=True, transform=transform)\n",
    "    client_data = []\n",
    "    samples_per_client = len(mnist_train) // num_clients\n",
    "    for i in range(num_clients):\n",
    "        indices = range(i * samples_per_client, (i+1) * samples_per_client)\n",
    "        client_data.append(Subset(mnist_train, indices))\n",
    "    \n",
    "    client_loaders = [DataLoader(data, batch_size=32, shuffle=True, drop_last=True) for data in client_data]\n",
    "    return client_loaders\n",
    "\n",
    "def get_imbalanced(num_clients=12):\n",
    "    transform = transforms.ToTensor()\n",
    "    mnist_train = datasets.MNIST(root='./data_mnist', train=True, download=True, transform=transform)\n",
    "    samples_per_client = len(mnist_train) // num_clients\n",
    "    common_data, validation_data = Subset(mnist_train, range(0 * samples_per_client, (0+1) * samples_per_client)), Subset(mnist_train, range(1 * samples_per_client, (1+1) * samples_per_client))\n",
    "    clients_dataset = Subset(mnist_train, range(2 * samples_per_client, (num_clients+1) * samples_per_client))\n",
    "\n",
    "    labels = torch.tensor([label for _, label in clients_dataset])\n",
    "    sorted_indices = torch.argsort(labels)\n",
    "    sorted_dataset = Subset(clients_dataset, sorted_indices)\n",
    "    client_data = []\n",
    "    \n",
    "    for i in range(num_clients - 2):\n",
    "        indices = range(i * samples_per_client, (i+1) * samples_per_client)\n",
    "        client_data.append(Subset(sorted_dataset, indices))\n",
    "\n",
    "    client_data.append(common_data)\n",
    "    client_data.append(validation_data)\n",
    "    client_loaders = [DataLoader(data, batch_size=32, shuffle=True, drop_last=True) for data in client_data]\n",
    "    return client_loaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_train(model, loader, epochs=1):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "flatten_list = lambda obj: list(itertools.chain.from_iterable(obj))\n",
    "\n",
    "def server_update(global_model, client_logits, client_inputs, lr=0.01):\n",
    "    client_logits = flatten_list(client_logits)\n",
    "    client_inputs = flatten_list(client_inputs)\n",
    "    optimizer = optim.SGD(global_model.parameters(), lr=lr)\n",
    "    mse_loss = nn.MSELoss()\n",
    "    global_model.train()\n",
    "    for x, y in zip(client_inputs, client_logits):\n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        server_logits = global_model(x)\n",
    "        loss = mse_loss(server_logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "differrent_num_clients = [10]\n",
    "num_clients_balanced_our = {}\n",
    "num_clients_imbalanced_our = {}\n",
    "num_clients_balanced_their = {}\n",
    "num_clients_imbalanced_their = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_clients in differrent_num_clients:\n",
    "    client_loaders = get_imbalanced(num_clients + 2)\n",
    "    common_loader = client_loaders[-2]\n",
    "    validation_loder = client_loaders[-1]\n",
    "    client_models = [SimpleCNN().to(device) for _ in range(num_clients)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.963942307692307"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_models = [SimpleCNN().to(device) for _ in range(num_clients)]\n",
    "node_accuracy = [evaluate(client_models[i], validation_loder) * 100 for i in range(num_clients)]\n",
    "sum(node_accuracy) / len(node_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_loaders = get_client_loaders(num_clients + 2)\n",
    "common_loader = client_loaders[-2]\n",
    "validation_loder = client_loaders[-1]\n",
    "client_models = [SimpleCNN().to(device) for _ in range(num_clients)]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def comp_rand_k(logits, k = 3):\n",
    "    seed = random.randint(0, 1000)\n",
    "    torch.manual_seed(seed)\n",
    "    size = logits.size()\n",
    "    new_size = size[:-1] + (k,)\n",
    "    sparse_logits = torch.zeros(new_size, dtype= logits.dtype)\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            indices = torch.randperm(size[-1], device=logits.device)[:k]\n",
    "            indices, _ = torch.sort(indices)\n",
    "            sparse_logits[i, j] = logits[i, j, indices]\n",
    "    sparse_logits *= size[-1] / k\n",
    "    return sparse_logits, seed, size\n",
    "\n",
    "def decomp_rand_k(sparse_logits, seed, size, k = 3):\n",
    "    torch.manual_seed(seed)\n",
    "    decomp_logits  = torch.full(size, float('-inf') ,dtype= sparse_logits.dtype)\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            indices = torch.randperm(size[-1], device=sparse_logits.device)[:k]\n",
    "            indices, _ = torch.sort(indices)\n",
    "            decomp_logits[i, j, indices] = sparse_logits[i, j]\n",
    "    return decomp_logits"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def comp_top_k(logits, k = 3):\n",
    "    size = logits.size()\n",
    "    _, indices = torch.topk(logits, k, dim= -1)\n",
    "    sparse_logits = torch.gather(logits, dim=-1, index=indices).to(logits.device)\n",
    "    return sparse_logits, indices, size\n",
    "\n",
    "\n",
    "def decomp_top_k(sparse_logits, indices, size):\n",
    "    decomp_logits  = torch.full(size, float('-inf'), dtype= sparse_logits.dtype, device= sparse_logits.device)\n",
    "    decomp_logits.scatter_(-1, indices, sparse_logits)\n",
    "    return decomp_logits"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def dithering(logits, b = 2, s = 8, p = 2):\n",
    "    norm_logits = torch.norm(logits.float(), p, dim=-1, keepdim=True)\n",
    "    normalized_logits = logits.abs() / norm_logits\n",
    "    levels = b ** -torch.arange(1, s + 1, dtype=logits.dtype, device=logits.device)  \n",
    "    levels = torch.cat([torch.tensor([1.0], device=logits.device, dtype=logits.dtype), levels, torch.tensor([0.0], device=logits.device, dtype=logits.dtype)])\n",
    "    u = torch.sum(normalized_logits.unsqueeze(-1) <= levels.unsqueeze(0), dim=-1, dtype= float) \n",
    "    lower = b ** -u\n",
    "    upper = b ** -(u - 1)\n",
    "    lower = torch.where(u == 10, 0.0, lower)\n",
    "    probs_upper = (normalized_logits - lower) / (upper - lower)\n",
    "    bern = torch.bernoulli(probs_upper)\n",
    "    quantized = torch.where(bern == 1, upper, lower)\n",
    "    result = norm_logits * torch.sign(logits) * quantized\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientState:\n",
    "    def __init__(self, model, lmbd = 0.1, gamma = 0.1):\n",
    "        self.weights = []\n",
    "        self.state = [torch.zeros_like(p) for p in model.parameters()]\n",
    "        self.prev_state = [torch.zeros_like(p) for p in model.parameters()]\n",
    "        self.lmbd = lmbd\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def local_step(self, model):\n",
    "        for idx, param in enumerate(model.parameters()):\n",
    "            self.state[idx] += param.grad - self.prev_state[idx]\n",
    "            self.prev_state[idx] = param.grad\n",
    "            param.grad = torch.zeros_like(param.grad)\n",
    "    \n",
    "    def global_step(self, model):\n",
    "        for idx, param in enumerate(model.parameters()):\n",
    "            self.state[idx] = param.grad\n",
    "            self.prev_state[idx] = param.grad\n",
    "            param.grad = torch.zeros_like(param.grad)\n",
    "\n",
    "    def set_weights(self, model):\n",
    "        self.weights = [p for p in model.parameters()]\n",
    "\n",
    "    def get_reg_term(self, model):\n",
    "        for idx, param in enumerate(model.parameters()):\n",
    "            self.state[idx] = param.grad\n",
    "            self.prev_state[idx] = param.grad\n",
    "            param.grad = torch.zeros_like(param.grad)\n",
    "\n",
    "        l2_regularization = torch.tensor(0., requires_grad=True)\n",
    "        for idx, (param, x, g) in enumerate(zip(model.parameters(), self.weights, self.state)):\n",
    "            l2_regularization = l2_regularization + torch.norm(param - (x - self.gamma * self.lmbd * g), p=2)\n",
    "        return l2_regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 20:19:05.919815: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-06 20:19:05.938882: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754511545.957599  516159 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754511545.963474  516159 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754511545.978085  516159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754511545.978100  516159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754511545.978102  516159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754511545.978103  516159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-06 20:19:05.983461: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "clients_states = [ClientState(model) for model in client_models]\n",
    "client_optimizers = [\n",
    "    optim.Adam(model.parameters())\n",
    "    for model in client_models\n",
    "]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def sync_clients(batch):\n",
    "    inputs, target = batch\n",
    "    inputs = inputs.to(device)\n",
    "    target = target.to(device)\n",
    "    logits = []\n",
    "    for model in client_models:\n",
    "        logits.append(model(inputs))\n",
    "    # print(logits[0].shape)\n",
    "    logits = torch.stack(logits)\n",
    "    sparse_logits = comp_rand_k(logits)\n",
    "    sparse_logits = decomp_top_k(*sparse_logits)\n",
    "    logits = sparse_logits.mean(0)\n",
    "    loss = criterion(logits, target)\n",
    "    loss.backward()\n",
    "\n",
    "def update_state():\n",
    "    for model_idx, model in enumerate(client_models):\n",
    "        for idx, param in enumerate(model.parameters):\n",
    "            clients_states[model_idx][idx] += param.grad\n",
    "\n",
    "def compute_accuracy():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in validation_loder:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = torch.stack([model(x) for model in client_models]).mean(0)\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "def run_step(p, iter_idx):\n",
    "    if random.random() > p:\n",
    "        # TODO: \n",
    "        batch = next(iter(common_loader))\n",
    "        sync_clients(batch)\n",
    "        for model, state in zip(client_models, clients_states):\n",
    "            state.global_step(model)\n",
    "    else:\n",
    "        for model, state, loader in zip(client_models, clients_states, client_loaders):\n",
    "            inputs, target = next(iter(loader))\n",
    "            inputs = inputs.to(device)\n",
    "            target = target.to(device)\n",
    "            # print(inputs)\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, target)\n",
    "            loss.backward()\n",
    "            state.local_step(model)\n",
    "    \n",
    "    for model, state, loader, optimizer in zip(client_models, clients_states, client_loaders, client_optimizers):\n",
    "        state.set_weights(model)\n",
    "        for _ in range(3):\n",
    "            inputs, target = next(iter(loader))\n",
    "            inputs = inputs.to(device)\n",
    "            target = target.to(device)\n",
    "            # for inputs, target in loader:\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, target)\n",
    "            reg = state.get_reg_term(model)\n",
    "            loss += reg\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    global_acc = compute_accuracy()\n",
    "    local_accuracy = torch.tensor([evaluate(model, loader) for model, loader in zip(client_models, client_loaders)])\n",
    "    writer.add_scalars(\n",
    "        main_tag='Accuracy',\n",
    "        tag_scalar_dict={'local': local_accuracy.mean(), 'ensembled': global_acc},\n",
    "        global_step=iter_idx\n",
    "    )\n",
    "    print(f\"Accuracy = {global_acc} Local accuracy = {local_accuracy.mean()} +- {local_accuracy.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6137820512820513 Local accuracy = 0.2643830180168152 +- 0.08397138118743896\n",
      "Accuracy = 0.5308493589743589 Local accuracy = 0.3551081717014313 +- 0.12408051639795303\n",
      "Accuracy = 0.7684294871794872 Local accuracy = 0.4624399244785309 +- 0.13731791079044342\n",
      "Accuracy = 0.7419871794871795 Local accuracy = 0.5452324151992798 +- 0.07956598699092865\n",
      "Accuracy = 0.7672275641025641 Local accuracy = 0.6132612228393555 +- 0.08989808708429337\n",
      "Accuracy = 0.84375 Local accuracy = 0.6686698198318481 +- 0.07870286703109741\n",
      "Accuracy = 0.8439503205128205 Local accuracy = 0.7227363586425781 +- 0.0580935962498188\n",
      "Accuracy = 0.8537660256410257 Local accuracy = 0.7209335565567017 +- 0.08218414336442947\n",
      "Accuracy = 0.8699919871794872 Local accuracy = 0.7552484273910522 +- 0.043463435024023056\n",
      "Accuracy = 0.8635817307692307 Local accuracy = 0.7574719190597534 +- 0.04214155673980713\n",
      "Accuracy = 0.8840144230769231 Local accuracy = 0.7871193885803223 +- 0.04737617075443268\n",
      "Accuracy = 0.8860176282051282 Local accuracy = 0.8094951510429382 +- 0.031430404633283615\n",
      "Accuracy = 0.8942307692307693 Local accuracy = 0.8194711804389954 +- 0.0220028143376112\n",
      "Accuracy = 0.8982371794871795 Local accuracy = 0.8284053802490234 +- 0.02421424724161625\n",
      "Accuracy = 0.8958333333333334 Local accuracy = 0.825580894947052 +- 0.026796072721481323\n",
      "Accuracy = 0.9030448717948718 Local accuracy = 0.8347957730293274 +- 0.017263000831007957\n",
      "Accuracy = 0.9072516025641025 Local accuracy = 0.8444511294364929 +- 0.01937725767493248\n",
      "Accuracy = 0.9096554487179487 Local accuracy = 0.8514022827148438 +- 0.016428133472800255\n",
      "Accuracy = 0.9116586538461539 Local accuracy = 0.8514221906661987 +- 0.02142026461660862\n",
      "Accuracy = 0.9154647435897436 Local accuracy = 0.860156238079071 +- 0.017057565972208977\n",
      "Accuracy = 0.913261217948718 Local accuracy = 0.8596354722976685 +- 0.014870581217110157\n",
      "Accuracy = 0.9142628205128205 Local accuracy = 0.8578726053237915 +- 0.018627364188432693\n",
      "Accuracy = 0.9160657051282052 Local accuracy = 0.8641826510429382 +- 0.01684149168431759\n",
      "Accuracy = 0.9150641025641025 Local accuracy = 0.8658252954483032 +- 0.023013677448034286\n",
      "Accuracy = 0.9156650641025641 Local accuracy = 0.868209183216095 +- 0.021568458527326584\n",
      "Accuracy = 0.9178685897435898 Local accuracy = 0.870072066783905 +- 0.01666402257978916\n",
      "Accuracy = 0.9186698717948718 Local accuracy = 0.8780649304389954 +- 0.017458437010645866\n",
      "Accuracy = 0.9194711538461539 Local accuracy = 0.8821113705635071 +- 0.010758312419056892\n",
      "Accuracy = 0.9190705128205128 Local accuracy = 0.8826923370361328 +- 0.007757347077131271\n",
      "Accuracy = 0.9222756410256411 Local accuracy = 0.8862580060958862 +- 0.012980472296476364\n",
      "Accuracy = 0.9230769230769231 Local accuracy = 0.8842747807502747 +- 0.013211039826273918\n",
      "Accuracy = 0.9234775641025641 Local accuracy = 0.8875400424003601 +- 0.009233219549059868\n",
      "Accuracy = 0.9236778846153846 Local accuracy = 0.8845952749252319 +- 0.01038728840649128\n",
      "Accuracy = 0.9228766025641025 Local accuracy = 0.8885817527770996 +- 0.011219855397939682\n",
      "Accuracy = 0.9242788461538461 Local accuracy = 0.8911458253860474 +- 0.016927355900406837\n",
      "Accuracy = 0.9272836538461539 Local accuracy = 0.8925479650497437 +- 0.012786098755896091\n",
      "Accuracy = 0.9268830128205128 Local accuracy = 0.8928284645080566 +- 0.012059595435857773\n",
      "Accuracy = 0.9278846153846154 Local accuracy = 0.8929487466812134 +- 0.00975633691996336\n",
      "Accuracy = 0.9298878205128205 Local accuracy = 0.8989183306694031 +- 0.010426158085465431\n",
      "Accuracy = 0.9280849358974359 Local accuracy = 0.8906650543212891 +- 0.019781822338700294\n",
      "Accuracy = 0.9278846153846154 Local accuracy = 0.8932692408561707 +- 0.013468666933476925\n",
      "Accuracy = 0.9278846153846154 Local accuracy = 0.8932892680168152 +- 0.014610137790441513\n",
      "Accuracy = 0.9272836538461539 Local accuracy = 0.8930289149284363 +- 0.016187580302357674\n",
      "Accuracy = 0.9270833333333334 Local accuracy = 0.8950520753860474 +- 0.012041629292070866\n",
      "Accuracy = 0.930488782051282 Local accuracy = 0.900981605052948 +- 0.015078112483024597\n",
      "Accuracy = 0.9322916666666666 Local accuracy = 0.9015825390815735 +- 0.015609591268002987\n",
      "Accuracy = 0.9310897435897436 Local accuracy = 0.9008011817932129 +- 0.014591125771403313\n",
      "Accuracy = 0.9334935897435898 Local accuracy = 0.9036858677864075 +- 0.010221267119050026\n",
      "Accuracy = 0.9316907051282052 Local accuracy = 0.9041668176651001 +- 0.00910922884941101\n",
      "Accuracy = 0.9320913461538461 Local accuracy = 0.9026442766189575 +- 0.010793373920023441\n",
      "Accuracy = 0.9318910256410257 Local accuracy = 0.9050080180168152 +- 0.014334652572870255\n",
      "Accuracy = 0.930488782051282 Local accuracy = 0.9055288434028625 +- 0.009954490698873997\n",
      "Accuracy = 0.9348958333333334 Local accuracy = 0.9000000953674316 +- 0.01456269808113575\n",
      "Accuracy = 0.936698717948718 Local accuracy = 0.90296471118927 +- 0.013390111736953259\n",
      "Accuracy = 0.9370993589743589 Local accuracy = 0.9131210446357727 +- 0.007589917629957199\n",
      "Accuracy = 0.9348958333333334 Local accuracy = 0.9078725576400757 +- 0.011652490124106407\n",
      "Accuracy = 0.9360977564102564 Local accuracy = 0.9099758863449097 +- 0.014639143832027912\n",
      "Accuracy = 0.9372996794871795 Local accuracy = 0.9136818647384644 +- 0.01277607399970293\n",
      "Accuracy = 0.9372996794871795 Local accuracy = 0.9160857200622559 +- 0.0089194281026721\n",
      "Accuracy = 0.9370993589743589 Local accuracy = 0.912580132484436 +- 0.012273331172764301\n",
      "Accuracy = 0.9362980769230769 Local accuracy = 0.9085737466812134 +- 0.011025207117199898\n",
      "Accuracy = 0.9368990384615384 Local accuracy = 0.9092747569084167 +- 0.007867074571549892\n",
      "Accuracy = 0.9370993589743589 Local accuracy = 0.9121394157409668 +- 0.010530411265790462\n",
      "Accuracy = 0.9372996794871795 Local accuracy = 0.9122797250747681 +- 0.015147855505347252\n",
      "Accuracy = 0.9338942307692307 Local accuracy = 0.9131210446357727 +- 0.010713791474699974\n",
      "Accuracy = 0.9336939102564102 Local accuracy = 0.9118989706039429 +- 0.00971402321010828\n",
      "Accuracy = 0.9372996794871795 Local accuracy = 0.913481593132019 +- 0.012463030405342579\n",
      "Accuracy = 0.9381009615384616 Local accuracy = 0.9141024351119995 +- 0.01240974385291338\n",
      "Accuracy = 0.9372996794871795 Local accuracy = 0.9121193885803223 +- 0.01678421162068844\n",
      "Accuracy = 0.9377003205128205 Local accuracy = 0.9165463447570801 +- 0.010327344760298729\n",
      "Accuracy = 0.9379006410256411 Local accuracy = 0.9188702702522278 +- 0.01120483037084341\n",
      "Accuracy = 0.9385016025641025 Local accuracy = 0.9165064096450806 +- 0.012790489941835403\n",
      "Accuracy = 0.9358974358974359 Local accuracy = 0.908052921295166 +- 0.017917463555932045\n",
      "Accuracy = 0.9381009615384616 Local accuracy = 0.9049479365348816 +- 0.01894044131040573\n",
      "Accuracy = 0.9391025641025641 Local accuracy = 0.9167668223381042 +- 0.01686219312250614\n",
      "Accuracy = 0.9407051282051282 Local accuracy = 0.916145920753479 +- 0.02011604979634285\n",
      "Accuracy = 0.9417067307692307 Local accuracy = 0.9170271754264832 +- 0.018233397975564003\n",
      "Accuracy = 0.9413060897435898 Local accuracy = 0.9208734631538391 +- 0.016581621021032333\n",
      "Accuracy = 0.9407051282051282 Local accuracy = 0.9232771992683411 +- 0.015047031454741955\n",
      "Accuracy = 0.9405048076923077 Local accuracy = 0.9206730723381042 +- 0.016954945400357246\n",
      "Accuracy = 0.9419070512820513 Local accuracy = 0.9248195886611938 +- 0.00971919298171997\n",
      "Accuracy = 0.9421073717948718 Local accuracy = 0.9240185022354126 +- 0.01237565092742443\n",
      "Accuracy = 0.9415064102564102 Local accuracy = 0.9202925562858582 +- 0.01399329025298357\n",
      "Accuracy = 0.9429086538461539 Local accuracy = 0.9250200986862183 +- 0.011580175720155239\n",
      "Accuracy = 0.9425080128205128 Local accuracy = 0.9247997403144836 +- 0.013545380905270576\n",
      "Accuracy = 0.9413060897435898 Local accuracy = 0.9236778020858765 +- 0.013588042929768562\n",
      "Accuracy = 0.9415064102564102 Local accuracy = 0.9270032048225403 +- 0.012476536445319653\n",
      "Accuracy = 0.9423076923076923 Local accuracy = 0.9271033406257629 +- 0.011876475997269154\n",
      "Accuracy = 0.9431089743589743 Local accuracy = 0.9254206418991089 +- 0.01249718852341175\n",
      "Accuracy = 0.944511217948718 Local accuracy = 0.9261218309402466 +- 0.01391351968050003\n",
      "Accuracy = 0.944511217948718 Local accuracy = 0.9282451868057251 +- 0.010905071161687374\n",
      "Accuracy = 0.9449118589743589 Local accuracy = 0.9292469024658203 +- 0.009801296517252922\n",
      "Accuracy = 0.9437099358974359 Local accuracy = 0.9285656809806824 +- 0.010663371533155441\n",
      "Accuracy = 0.9435096153846154 Local accuracy = 0.928625762462616 +- 0.009671351872384548\n",
      "Accuracy = 0.9453125 Local accuracy = 0.9298878908157349 +- 0.008933193981647491\n",
      "Accuracy = 0.9453125 Local accuracy = 0.9310296773910522 +- 0.008257828652858734\n",
      "Accuracy = 0.9469150641025641 Local accuracy = 0.9308093786239624 +- 0.010299671441316605\n",
      "Accuracy = 0.9465144230769231 Local accuracy = 0.9327523112297058 +- 0.011860902421176434\n",
      "Accuracy = 0.944511217948718 Local accuracy = 0.933293342590332 +- 0.009121368639171124\n",
      "Accuracy = 0.9455128205128205 Local accuracy = 0.932572066783905 +- 0.008688868954777718\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    run_step(0.2, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
